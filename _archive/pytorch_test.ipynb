{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testfile - to be edited"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are in the yolo format:<br />\n",
    "In this format, each line represents a bounding box with the following values: <br/><ul>\n",
    "    <li>class</li>\n",
    "    <li>center_x</li>\n",
    "    <li>center_y</li>\n",
    "    <li>width</li>\n",
    "    <li>height</li>\n",
    "</ul> All coordinates are normalized relative to the image dimensions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lukas\\anaconda3\\envs\\hslu-maldasc_project\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image & Label directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = '_pytorch_bland/images'\n",
    "ann_root = '_pytorch_bland/labels'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolarPanelDataset(Dataset):\n",
    "    def __init__(self, img_root, ann_root, transform=None):\n",
    "        self.img_root = img_root\n",
    "        self.ann_root = ann_root\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([os.path.join(img_root, file) for file in os.listdir(img_root) if file.endswith('.jpg')])\n",
    "        self.ann_files = sorted([os.path.join(ann_root, file) for file in os.listdir(ann_root) if file.endswith('.txt')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Load and process the annotations for this image\n",
    "        ann_path = self.ann_files[idx]\n",
    "        boxes = []  # List of bounding boxes\n",
    "        labels = []  # List of labels (1 for solar panel)\n",
    "\n",
    "        # Load and process the annotations (YOLO format)\n",
    "        with open(ann_path, 'r') as f:\n",
    "            for line in f:\n",
    "                label, cx, cy, w, h = map(float, line.strip().split())\n",
    "                x1 = (cx - w / 2) * img.width\n",
    "                y1 = (cy - h / 2) * img.height\n",
    "                x2 = (cx + w / 2) * img.width\n",
    "                y2 = (cy + h / 2) * img.height\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                # Add 1 to the label to ensure it starts from 1\n",
    "                adjusted_label = int(label) + 1\n",
    "                labels.append(adjusted_label)\n",
    "\n",
    "        # Handle cases where there are no bounding boxes\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            iscrowd = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            iscrowd = torch.zeros(len(boxes), dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'iscrowd': iscrowd\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = SolarPanelDataset(img_root, ann_root, transform=transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data: We build a data & training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loaders for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for the training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture<br />\n",
    "According to Medium (https://medium.com/ibm-data-ai/faster-r-cnn-vs-yolo-vs-ssd-object-detection-algorithms-18badb0e02dc) we should use a faster R-CNN for Object Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\Lukas/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Create the Faster R-CNN model\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "backbone.out_channels = 1280\n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "num_classes = 6  # 5 classes + 1 for background\n",
    "model = FasterRCNN(backbone, num_classes=num_classes, rpn_anchor_generator=anchor_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 23512, 14492, 21508, 16672) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1134\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     23\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     25\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(image\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images)\n\u001b[0;32m     26\u001b[0m     targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1296\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\anaconda3\\envs\\hslu-maldasc_project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 23512, 14492, 21508, 16672) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "def get_faster_rcnn_model(num_classes):\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "num_classes = 2  # Background class (0) and solar panel class (1)\n",
    "model = get_faster_rcnn_model(num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += losses.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hslu-maldasc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
